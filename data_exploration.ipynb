{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "941df59c7c1a1c2a"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-10T13:06:57.119779417Z",
     "start_time": "2024-02-10T13:06:53.990952534Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-10 14:06:54.847871: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-10 14:06:55.104984: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-10 14:06:55.105045: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-10 14:06:55.152269: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-10 14:06:55.238028: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-10 14:06:55.239618: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-10 14:06:56.364383: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from upload_overleaf.upload import upload\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow has access to the following devices:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n"
     ]
    }
   ],
   "source": [
    "print(f'TensorFlow has access to the following devices:\\n{tf.config.list_physical_devices()}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T13:07:03.027353924Z",
     "start_time": "2024-02-10T13:07:03.018644912Z"
    }
   },
   "id": "c741018e3ed6edf1",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following cell reads the parquet files created by raw2parquet.py. \n",
    "\n",
    "It joins the prices and coacs tables on the ticker and date columns. It also creates a new column called OldNoOfStocks, which is the number of stocks before the stock split/dividend. If there is not a match in the coacs table, the OldNoOfStocks is set to 1. The StockOpen, StockHigh, StockLow, and StockClose columns are multiplied with OldNoOfStocks to get the adjusted price.\n",
    "\n",
    "It applies the log transformation to the adjusted prices, and the calculates the log return for each ticker. The log return is calculated for the following time intervals: 1, 5, 10, 30, 60, 120, 240, and 390 minutes. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "589b20038a8ad9de"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lf_intraday = (\n",
    "    pl.scan_parquet('prices.parquet')\n",
    "    .join(pl.scan_parquet('coacs.parquet').select(['ticker','date','OldNoOfStocks']), on=['ticker', 'date'], how='left')\n",
    "    # If there is not a match in the coacs table, the OldNoOfStocks is set to 1.\n",
    "    .with_columns(pl.when(pl.col('OldNoOfStocks').is_null()).then(1).otherwise(pl.col('OldNoOfStocks')).alias('OldNoOfStocks'))\n",
    "    # Multiply StockOpen, StockHigh, StockLow, and StockClose with OldNoOfStocks to get the adjusted price\n",
    "    .with_columns([\n",
    "        pl.col('StockClose') * pl.col('OldNoOfStocks').alias('StockClose')\n",
    "    ])\n",
    "    .with_columns([\n",
    "        pl.col('ticker'),\n",
    "        pl.col('date').alias('date'),\n",
    "        pl.col('datetime').alias('datetime'),\n",
    "        pl.col('StockClose').log().alias('log_close'),\n",
    "        pl.col('StockVol').alias('volume')\n",
    "    ])\n",
    "    .sort(['ticker', 'datetime'])\n",
    "    .select([\n",
    "        'ticker',\n",
    "        'date',\n",
    "        'datetime',\n",
    "        'log_close',\n",
    "        'volume',\n",
    "        (pl.col('log_close') - pl.col('log_close').shift(1)).over(pl.col('ticker')).alias('return_1min'),\n",
    "        (pl.col('log_close') - pl.col('log_close').shift(5)).over(pl.col('ticker')).alias('return_5min'),\n",
    "        (pl.col('log_close') - pl.col('log_close').shift(10)).over(pl.col('ticker')).alias('return_10min'),\n",
    "        (pl.col('log_close') - pl.col('log_close').shift(30)).over(pl.col('ticker')).alias('return_30min'),\n",
    "        (pl.col('log_close') - pl.col('log_close').shift(60)).over(pl.col('ticker')).alias('return_1h'),\n",
    "        (pl.col('log_close') - pl.col('log_close').shift(120)).over(pl.col('ticker')).alias('return_2h'),\n",
    "        (pl.col('log_close') - pl.col('log_close').shift(240)).over(pl.col('ticker')).alias('return_4h'),\n",
    "        (pl.col('log_close') - pl.col('log_close').shift(390)).over(pl.col('ticker')).alias('return_1d')\n",
    "    ])\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T13:07:06.419025774Z",
     "start_time": "2024-02-10T13:07:06.380935979Z"
    }
   },
   "id": "22b9f5fb0f4b63c7",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Join SP500 data with the intraday data, and calculate the excess market return\n",
    "lf_intraday = (\n",
    "    lf_intraday\n",
    "    .join((lf_intraday.filter(pl.col('ticker') == 'US500')\n",
    "    .select([\n",
    "        pl.col('datetime').alias('datetime'),\n",
    "        pl.col('log_close').alias('mkt_log_close'),\n",
    "        pl.col('volume').alias('mkt_volume'),\n",
    "        pl.col('return_1min').alias('mkt_return_1min'),\n",
    "        pl.col('return_5min').alias('mkt_return_5min'),\n",
    "        pl.col('return_10min').alias('mkt_return_10min'),\n",
    "        pl.col('return_30min').alias('mkt_return_30min'),\n",
    "        pl.col('return_1h').alias('mkt_return_1h'),\n",
    "        pl.col('return_2h').alias('mkt_return_2h'),\n",
    "        pl.col('return_4h').alias('mkt_return_4h'),\n",
    "        pl.col('return_1d').alias('mkt_return_1d')\n",
    "    ])\n",
    "    ), on='datetime', how='left')\n",
    "    .with_columns([\n",
    "        pl.col('return_1min') - pl.col('mkt_return_1min').alias('excess_return_1min'),\n",
    "        pl.col('return_5min') - pl.col('mkt_return_5min').alias('excess_return_5min'),\n",
    "        pl.col('return_10min') - pl.col('mkt_return_10min').alias('excess_return_10min'),\n",
    "        pl.col('return_30min') - pl.col('mkt_return_30min').alias('excess_return_30min'),\n",
    "        pl.col('return_1h') - pl.col('mkt_return_1h').alias('excess_return_1h'),\n",
    "        pl.col('return_2h') - pl.col('mkt_return_2h').alias('excess_return_2h'),\n",
    "        pl.col('return_4h') - pl.col('mkt_return_4h').alias('excess_return_4h'),\n",
    "        pl.col('return_1d') - pl.col('mkt_return_1d').alias('excess_return_1d')\n",
    "    ])\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T13:07:07.738330014Z",
     "start_time": "2024-02-10T13:07:07.651124118Z"
    }
   },
   "id": "833b90b0ca10cb5",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mlf_intraday\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/MastersThesis/venv/lib/python3.11/site-packages/polars/lazyframe/frame.py:1940\u001B[0m, in \u001B[0;36mLazyFrame.collect\u001B[0;34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, no_optimization, streaming, background, _eager)\u001B[0m\n\u001B[1;32m   1937\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m background:\n\u001B[1;32m   1938\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m InProcessQuery(ldf\u001B[38;5;241m.\u001B[39mcollect_concurrently())\n\u001B[0;32m-> 1940\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m wrap_df(\u001B[43mldf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "lf_intraday.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T13:08:21.147282078Z",
     "start_time": "2024-02-10T13:07:47.499301934Z"
    }
   },
   "id": "7eaf12235efdfe80",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Subset every 60th row. This is done to reduce the size of the data for initial testing.\n",
    "lf_intraday = lf_intraday.gather_every(n=60).lazy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3333e9341bd5350",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following cell transforms the intraday data to daily data. It groups the data by date and ticker, and sums the volume to get the daily volume. It also calculates the daily return for each ticker."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b56717db45072f42"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    " # Group by date and ticker and sum volumne to get daily volume\n",
    "lf_daily = (\n",
    "    lf_intraday\n",
    "    .group_by(['ticker', 'date'])\n",
    "    .agg(\n",
    "        pl.last('datetime').alias('datetime'),\n",
    "        pl.last('log_close').cast(pl.Float64),\n",
    "        pl.sum('volume').cast(pl.Float64).alias('volume') # Sum volume to get daily volume\n",
    "    )\n",
    "    .group_by(['ticker', 'date']).last() # Select the last row in each group\n",
    "    .sort(['ticker', 'date'])\n",
    "    .select([\n",
    "        'ticker',\n",
    "        'date',\n",
    "        'datetime',\n",
    "        'log_close',\n",
    "        'volume',\n",
    "        (pl.col('log_close') - pl.col('log_close').shift(1)).over(pl.col('ticker')).alias('return_1d')\n",
    "    ])\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b2628096e21664a3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lf_daily.fetch(n_rows=10000)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "faa10d03ecdf56c0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_aapl = lf_daily.filter(pl.col('ticker') == 'AAPL').collect().to_pandas()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99595740e6193968",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plot time series of StockClose\n",
    "plt.figure(figsize=(15,10))\n",
    "# Add second y-axis. Left is log price and right is return\n",
    "ax = sns.lineplot(x='date', y='log_close', data=df_aapl, color='cornflowerblue')\n",
    "ax2 = ax.twinx()\n",
    "sns.lineplot(x='date', y='volume', data=df_aapl, color='red', ax=ax2, alpha=0.5)\n",
    "# Disable grid\n",
    "ax.grid(False)\n",
    "ax2.grid(False)\n",
    "ax.set_title('AAPL Stock Price and Volume')\n",
    "ax.set_ylabel('Log Price')\n",
    "ax2.set_ylabel('Volume')\n",
    "ax.set_xlabel('Date')\n",
    "upload(plt, \"Master's Thesis\", 'figures/aapl_test.png')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20adffb2d6d12d35",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "92d78d0ceb2edc8b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
